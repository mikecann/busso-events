import {
  internalQuery,
  internalMutation,
  internalAction,
} from "../_generated/server";
import { v } from "convex/values";
import { internal } from "../_generated/api";
import { Doc, Id } from "../_generated/dataModel";
import {
  SourceScrapeResult,
  TestScrapeResult,
  TestScrapeProgress,
  calculateNextScrapeTime,
  getInitialScrapeDelay,
  formatScrapeError,
  createSourceError,
  SOURCE_CONSTANTS,
} from "./common";

// INTERNAL QUERIES

export const getActiveSources = internalQuery({
  args: {},
  handler: async (ctx): Promise<Doc<"eventSources">[]> => {
    return await ctx.db
      .query("eventSources")
      .filter((q) => q.eq(q.field("isActive"), true))
      .collect();
  },
});

export const getSourceById = internalQuery({
  args: {
    sourceId: v.id("eventSources"),
  },
  handler: async (ctx, args): Promise<Doc<"eventSources"> | null> => {
    return await ctx.db.get(args.sourceId);
  },
});

export const getTestScrapeById = internalQuery({
  args: {
    testScrapeId: v.id("testScrapes"),
  },
  handler: async (ctx, args): Promise<Doc<"testScrapes"> | null> => {
    return await ctx.db.get(args.testScrapeId);
  },
});

// INTERNAL MUTATIONS

export const updateLastScrapeTime = internalMutation({
  args: {
    sourceId: v.id("eventSources"),
    timestamp: v.number(),
  },
  handler: async (ctx, args): Promise<void> => {
    console.log(
      `üîÑ updateLastScrapeTime called for sourceId: ${args.sourceId} at timestamp: ${new Date(args.timestamp).toISOString()}`,
    );

    await ctx.db.patch(args.sourceId, {
      dateLastScrape: args.timestamp,
    });

    console.log(`üìÖ Calling scheduleNextScrape for sourceId: ${args.sourceId}`);
    // Schedule next scrape in 3 days
    await scheduleNextScrape(ctx, args.sourceId);
  },
});

export const clearScheduledScrape = internalMutation({
  args: {
    sourceId: v.id("eventSources"),
  },
  handler: async (ctx, args): Promise<void> => {
    await ctx.db.patch(args.sourceId, {
      nextScrapeScheduledId: undefined,
      nextScrapeScheduledAt: undefined,
    });
  },
});

export const updateTestScrapeProgress = internalMutation({
  args: {
    testScrapeId: v.id("testScrapes"),
    progress: v.object({
      stage: v.string(),
      message: v.string(),
      eventsFound: v.optional(v.number()),
    }),
  },
  handler: async (ctx, args): Promise<void> => {
    await ctx.db.patch(args.testScrapeId, {
      status: "running",
      progress: args.progress,
    });
  },
});

export const completeTestScrape = internalMutation({
  args: {
    testScrapeId: v.id("testScrapes"),
    result: v.object({
      success: v.boolean(),
      message: v.string(),
      eventsFound: v.optional(v.number()),
      data: v.optional(v.any()),
    }),
  },
  handler: async (ctx, args): Promise<void> => {
    await ctx.db.patch(args.testScrapeId, {
      status: args.result.success ? "completed" : "failed",
      result: args.result,
      completedAt: Date.now(),
    });
  },
});

export const createTestScrape = internalMutation({
  args: {
    url: v.string(),
  },
  handler: async (ctx, args): Promise<Id<"testScrapes">> => {
    return await ctx.db.insert("testScrapes", {
      url: args.url,
      status: "pending",
      createdAt: Date.now(),
    });
  },
});

// INTERNAL ACTIONS

export const performSourceScrape = internalAction({
  args: {
    sourceId: v.id("eventSources"),
  },
  handler: async (ctx, args): Promise<SourceScrapeResult> => {
    try {
      console.log(`üîç Starting source scrape for sourceId: ${args.sourceId}`);

      // Get the source
      const source = await ctx.runQuery(
        internal.eventSources.eventSourcesInternal.getSourceById,
        {
          sourceId: args.sourceId,
        },
      );

      if (!source) {
        console.error(`‚ùå Event source not found: ${args.sourceId}`);
        return {
          success: false,
          message: `Event source with id '${args.sourceId}' not found`,
        };
      }

      console.log(`‚úÖ Found source: ${source.name} (${source.startingUrl})`);

      // Scrape the source page using the general URL scraping function
      console.log(`üåê Scraping URL: ${source.startingUrl}`);
      const scrapeResult = await ctx.runAction(
        internal.scraping.scrapingInternal.scrapeUrlInternal,
        { url: source.startingUrl },
      );

      if (!scrapeResult.success) {
        console.error(`‚ùå Scrape failed: ${scrapeResult.message}`);
        return {
          success: false,
          message: `Failed to scrape source URL: ${scrapeResult.message}`,
        };
      }

      console.log(
        `‚úÖ Scrape successful, content length: ${scrapeResult.data?.contentLength || 0}`,
      );

      // Extract events from the scraped data
      const events = scrapeResult.data?.extractedEvents || [];
      console.log(`üìù Found ${events.length} potential events`);

      let eventsCreated = 0;

      // Process each event found
      for (const eventData of events) {
        try {
          console.log(
            `üîÑ Processing event: ${eventData.title} (${eventData.url || "no URL"})`,
          );

          // Skip events without required fields
          if (!eventData.url || !eventData.title) {
            console.log(
              `‚è≠Ô∏è Skipping event with missing required fields: ${eventData.title || "no title"}`,
            );
            continue;
          }

          // Check if event already exists
          const existingEvent = await ctx.runQuery(
            internal.events.eventsInternal.getEventByUrl,
            {
              url: eventData.url,
            },
          );

          if (!existingEvent) {
            // Create new event
            console.log(`‚ûï Creating new event: ${eventData.title}`);

            // Parse event date
            let eventDate = Date.now() + 24 * 60 * 60 * 1000; // Default to tomorrow
            if (eventData.eventDate) {
              if (typeof eventData.eventDate === "string") {
                const parsedDate = new Date(eventData.eventDate);
                if (!isNaN(parsedDate.getTime())) {
                  eventDate = parsedDate.getTime();
                }
              } else if (typeof eventData.eventDate === "number") {
                eventDate = eventData.eventDate;
              }
            }

            await ctx.runMutation(
              internal.events.eventsInternal.createInternal,
              {
                title: eventData.title,
                description:
                  eventData.description ||
                  `Event: ${eventData.title}. More details available at ${eventData.url}`,
                eventDate: eventDate,
                imageUrl: eventData.imageUrl || "",
                url: eventData.url,
                sourceId: args.sourceId,
              },
            );
            eventsCreated++;
          } else {
            console.log(
              `‚è≠Ô∏è Event already exists, skipping: ${eventData.title}`,
            );
          }
        } catch (error) {
          console.error(
            `‚ùå Failed to process event ${eventData.url || "unknown URL"}:`,
            error,
          );
        }
      }

      // Update the source's last scrape time
      console.log(`üîÑ Updating last scrape time for source: ${source.name}`);
      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.updateLastScrapeTime,
        {
          sourceId: args.sourceId,
          timestamp: Date.now(),
        },
      );

      const message = `Successfully scraped source '${source.name}'. Created ${eventsCreated} new events from ${events.length} total events found.`;
      console.log(`‚úÖ ${message}`);

      return {
        success: true,
        message,
        eventsFound: eventsCreated,
        data: {
          sourceName: source.name,
          sourceUrl: source.startingUrl,
          totalEventsFound: events.length,
          newEventsCreated: eventsCreated,
          existingEventsSkipped: events.length - eventsCreated,
        },
      };
    } catch (error) {
      const errorMessage = formatScrapeError(args.sourceId, error);
      console.error(`‚ùå ${errorMessage}`);
      console.error("Error details:", error);

      return {
        success: false,
        message: errorMessage,
      };
    }
  },
});

export const performTestScrape = internalAction({
  args: {
    testScrapeId: v.id("testScrapes"),
  },
  handler: async (ctx, args): Promise<void> => {
    try {
      console.log(
        `üß™ Starting test scrape for testScrapeId: ${args.testScrapeId}`,
      );

      const testScrape = await ctx.runQuery(
        internal.eventSources.eventSourcesInternal.getTestScrapeById,
        {
          testScrapeId: args.testScrapeId,
        },
      );

      if (!testScrape) {
        throw new Error(`Test scrape with id '${args.testScrapeId}' not found`);
      }

      console.log(`‚úÖ Found test scrape for URL: ${testScrape.url}`);

      // Update progress: fetching
      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.updateTestScrapeProgress,
        {
          testScrapeId: args.testScrapeId,
          progress: {
            stage: "fetching",
            message: "Fetching content from URL...",
          },
        },
      );

      // Scrape the URL
      console.log(`üåê Scraping URL: ${testScrape.url}`);
      const scrapeResult = await ctx.runAction(
        internal.scraping.scrapingInternal.scrapeUrlInternal,
        { url: testScrape.url },
      );

      if (!scrapeResult.success) {
        console.error(`‚ùå Scrape failed: ${scrapeResult.message}`);
        await ctx.runMutation(
          internal.eventSources.eventSourcesInternal.completeTestScrape,
          {
            testScrapeId: args.testScrapeId,
            result: {
              success: false,
              message: `Failed to scrape URL: ${scrapeResult.message}`,
            },
          },
        );
        return;
      }

      // Update progress: extracting
      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.updateTestScrapeProgress,
        {
          testScrapeId: args.testScrapeId,
          progress: {
            stage: "extracting",
            message: "Extracting events from content...",
          },
        },
      );

      // Extract events from scraped data
      const events = scrapeResult.data?.extractedEvents || [];
      console.log(`üìù Found ${events.length} potential events`);

      // Update progress: processing
      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.updateTestScrapeProgress,
        {
          testScrapeId: args.testScrapeId,
          progress: {
            stage: "processing",
            message: `Found ${events.length} potential events`,
            eventsFound: events.length,
          },
        },
      );

      // Complete the test scrape
      const message = `Successfully scraped URL '${testScrape.url}'. Found ${events.length} potential events.`;
      console.log(`‚úÖ ${message}`);

      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.completeTestScrape,
        {
          testScrapeId: args.testScrapeId,
          result: {
            success: true,
            message,
            eventsFound: events.length,
            data: {
              url: testScrape.url,
              totalEventsFound: events.length,
              scrapedData: scrapeResult.data,
              extractedEvents: events,
            },
          },
        },
      );
    } catch (error) {
      const errorMessage = `Failed to scrape URL: ${error instanceof Error ? error.message : "Unknown error"}`;
      console.error(
        `‚ùå Test scrape failed for testScrapeId: ${args.testScrapeId}`,
        error,
      );

      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.completeTestScrape,
        {
          testScrapeId: args.testScrapeId,
          result: {
            success: false,
            message: errorMessage,
          },
        },
      );
    }
  },
});

export const performScheduledSourceScrape = internalAction({
  args: {
    sourceId: v.id("eventSources"),
  },
  handler: async (ctx, args): Promise<void> => {
    try {
      console.log(
        `‚è∞ Starting scheduled scrape for sourceId: ${args.sourceId}`,
      );

      // Get the source to verify it's still active
      const source = await ctx.runQuery(
        internal.eventSources.eventSourcesInternal.getSourceById,
        {
          sourceId: args.sourceId,
        },
      );

      if (!source) {
        console.log(
          `‚ùå Source not found for scheduled scrape: ${args.sourceId}`,
        );
        return;
      }

      if (!source.isActive) {
        console.log(
          `‚è∏Ô∏è Source is inactive, skipping scheduled scrape: ${source.name}`,
        );
        // Clear the scheduled scrape since source is inactive
        await ctx.runMutation(
          internal.eventSources.eventSourcesInternal.clearScheduledScrape,
          {
            sourceId: args.sourceId,
          },
        );
        return;
      }

      console.log(
        `‚úÖ Running scheduled scrape for active source: ${source.name}`,
      );

      // Perform the scrape using the existing scrape logic
      const result = await ctx.runAction(
        internal.eventSources.eventSourcesInternal.performSourceScrape,
        {
          sourceId: args.sourceId,
        },
      );

      if (result.success) {
        console.log(
          `‚úÖ Scheduled scrape completed successfully for ${source.name}: ${result.message}`,
        );
      } else {
        console.error(
          `‚ùå Scheduled scrape failed for ${source.name}: ${result.message}`,
        );
      }

      // Clear the scheduled scrape info since this job is now complete
      // The performSourceScrape -> updateLastScrapeTime chain will schedule the next one
      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.clearScheduledScrape,
        {
          sourceId: args.sourceId,
        },
      );
    } catch (error) {
      console.error(
        `üí• Error in scheduled source scrape for ${args.sourceId}:`,
        error,
      );

      // Clear the scheduled scrape info even on error to prevent stuck jobs
      await ctx.runMutation(
        internal.eventSources.eventSourcesInternal.clearScheduledScrape,
        {
          sourceId: args.sourceId,
        },
      );
    }
  },
});

// Helper function to schedule next scraping for a source
async function scheduleNextScrape(
  ctx: any,
  sourceId: Id<"eventSources">,
): Promise<void> {
  console.log(`üìÖ scheduleNextScrape called for sourceId: ${sourceId}`);

  const source = await ctx.db.get(sourceId);
  if (!source) {
    console.log(`‚ùå Source not found: ${sourceId}`);
    return;
  }

  if (!source.isActive) {
    console.log(`‚è∏Ô∏è Source is inactive, skipping scheduling: ${source.name}`);
    return;
  }

  console.log(`‚úÖ Scheduling next scrape for active source: ${source.name}`);

  // Cancel any existing scheduled scraping for this source
  if (source.nextScrapeScheduledId) {
    try {
      console.log(
        `üóëÔ∏è Canceling existing scheduled scrape: ${source.nextScrapeScheduledId}`,
      );
      await ctx.scheduler.cancel(source.nextScrapeScheduledId);
    } catch (error) {
      // Ignore errors if the job was already completed or doesn't exist
      console.log("Could not cancel existing scrape job:", error);
    }
  }

  // Schedule next scraping in 3 days (72 hours)
  const delayMs =
    SOURCE_CONSTANTS.DEFAULT_SCRAPE_INTERVAL_DAYS * 24 * 60 * 60 * 1000;
  const scheduledId = await ctx.scheduler.runAfter(
    delayMs,
    internal.eventSources.eventSourcesInternal.performScheduledSourceScrape,
    { sourceId },
  );

  console.log(
    `‚è∞ Scheduled next scrape with ID: ${scheduledId}, delay: ${delayMs}ms (${SOURCE_CONSTANTS.DEFAULT_SCRAPE_INTERVAL_DAYS} days)`,
  );

  // Update the source with the scheduled job info
  await ctx.db.patch(sourceId, {
    nextScrapeScheduledId: scheduledId,
    nextScrapeScheduledAt: Date.now() + delayMs,
  });

  console.log(
    `‚úÖ Successfully scheduled next scrape for ${source.name} at ${new Date(Date.now() + delayMs).toISOString()}`,
  );
}
